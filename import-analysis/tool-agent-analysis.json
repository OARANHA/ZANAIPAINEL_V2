{
  "id": "imported_1755634028664_spd7ygm6h",
  "name": "Tool Agent",
  "description": "Agent that uses Function Calling to pick the tools and args to call",
  "type": "AGENTFLOW",
  "category": "Tools",
  "nodes": [
    {
      "id": "calculator_1",
      "type": "customNode",
      "position": {
        "x": 800.5125025564965,
        "y": 72.40592063242738
      },
      "positionAbsolute": {
        "x": 800.5125025564965,
        "y": 72.40592063242738
      },
      "width": 300,
      "height": 149,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "calculator_1",
        "label": "Calculator",
        "version": 1,
        "name": "calculator",
        "type": "Calculator",
        "baseClasses": [
          "Calculator",
          "Tool",
          "StructuredTool",
          "BaseLangChain"
        ],
        "category": "Tools",
        "description": "Perform calculations on response",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "calculator_1-output-calculator-Calculator|Tool|StructuredTool|BaseLangChain",
            "name": "calculator",
            "label": "Calculator",
            "type": "Calculator | Tool | StructuredTool | BaseLangChain"
          }
        ],
        "outputs": {},
        "selected": false
      }
    },
    {
      "id": "bufferMemory_1",
      "type": "customNode",
      "position": {
        "x": 607.6260576768354,
        "y": 584.7920541862369
      },
      "positionAbsolute": {
        "x": 607.6260576768354,
        "y": 584.7920541862369
      },
      "width": 300,
      "height": 258,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "bufferMemory_1",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_1-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_1-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      }
    },
    {
      "id": "serpAPI_0",
      "type": "customNode",
      "position": {
        "x": 439.29908455642476,
        "y": 48.06000078669291
      },
      "positionAbsolute": {
        "x": 439.29908455642476,
        "y": 48.06000078669291
      },
      "width": 300,
      "height": 281,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "serpAPI_0",
        "label": "Serp API",
        "version": 1,
        "name": "serpAPI",
        "type": "SerpAPI",
        "baseClasses": [
          "SerpAPI",
          "Tool",
          "StructuredTool"
        ],
        "category": "Tools",
        "description": "Wrapper around SerpAPI - a real-time API to access Google search results",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "serpApi"
            ],
            "id": "serpAPI_0-input-credential-credential"
          }
        ],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool",
            "name": "serpAPI",
            "label": "SerpAPI",
            "type": "SerpAPI | Tool | StructuredTool"
          }
        ],
        "outputs": {},
        "selected": false
      }
    },
    {
      "id": "chatOpenAI_0",
      "type": "customNode",
      "position": {
        "x": 97.01321406237057,
        "y": 63.67664262280914
      },
      "positionAbsolute": {
        "x": 97.01321406237057,
        "y": 63.67664262280914
      },
      "width": 300,
      "height": 771,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.2,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": true
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": true,
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      }
    },
    {
      "id": "stickyNote_0",
      "type": "stickyNote",
      "position": {
        "x": 1197.3578961103253,
        "y": 117.43214592301385
      },
      "positionAbsolute": {
        "x": 1197.3578961103253,
        "y": 117.43214592301385
      },
      "width": 300,
      "height": 62,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "stickyNote_0",
        "label": "Sticky Note",
        "version": 2,
        "name": "stickyNote",
        "type": "StickyNote",
        "baseClasses": [
          "StickyNote"
        ],
        "category": "Utilities",
        "description": "Add a sticky note",
        "inputParams": [
          {
            "label": "",
            "name": "note",
            "type": "string",
            "rows": 1,
            "placeholder": "Type something here",
            "optional": true,
            "id": "stickyNote_0-input-note-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "note": "LLM has to be function calling compatible"
        },
        "outputAnchors": [
          {
            "id": "stickyNote_0-output-stickyNote-StickyNote",
            "name": "stickyNote",
            "label": "StickyNote",
            "description": "Add a sticky note",
            "type": "StickyNote"
          }
        ],
        "outputs": {},
        "selected": false,
        "tags": [
          "Utilities"
        ]
      }
    },
    {
      "id": "toolAgent_0",
      "type": "customNode",
      "position": {
        "x": 1200.6756893536506,
        "y": 208.18578883272318
      },
      "positionAbsolute": {
        "x": 1200.6756893536506,
        "y": 208.18578883272318
      },
      "width": 300,
      "height": 491,
      "selected": false,
      "dragging": false,
      "data": {
        "id": "toolAgent_0",
        "label": "Tool Agent",
        "version": 2,
        "name": "toolAgent",
        "type": "AgentExecutor",
        "baseClasses": [
          "AgentExecutor",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "default": "You are a helpful AI assistant.",
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "rows": 4,
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-systemMessage-string",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-maxIterations-number",
            "display": true
          },
          {
            "label": "Enable Detailed Streaming",
            "name": "enableDetailedStreaming",
            "type": "boolean",
            "default": false,
            "description": "Stream detailed intermediate steps during agent execution",
            "optional": true,
            "additionalParams": true,
            "id": "toolAgent_0-input-enableDetailedStreaming-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "toolAgent_0-input-tools-Tool",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "toolAgent_0-input-memory-BaseChatMemory",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
            "id": "toolAgent_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Count text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "toolAgent_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "tools": [
            "{{calculator_1.data.instance}}",
            "{{serpAPI_0.data.instance}}"
          ],
          "memory": "{{bufferMemory_1.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "",
          "systemMessage": "You are a helpful AI assistant.",
          "inputModeration": "",
          "maxIterations": "",
          "enableDetailedStreaming": ""
        },
        "outputAnchors": [
          {
            "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
            "name": "toolAgent",
            "label": "AgentExecutor",
            "description": "Agent that uses Function Calling to pick the tools and args to call",
            "type": "AgentExecutor | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      }
    }
  ],
  "edges": [
    {
      "id": "calculator_1-calculator_1-output-calculator-Calculator|Tool|StructuredTool|BaseLangChain-toolAgent_0-toolAgent_0-input-tools-Tool",
      "source": "calculator_1",
      "target": "toolAgent_0",
      "sourceHandle": "calculator_1-output-calculator-Calculator|Tool|StructuredTool|BaseLangChain",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "data": {}
    },
    {
      "id": "serpAPI_0-serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool-toolAgent_0-toolAgent_0-input-tools-Tool",
      "source": "serpAPI_0",
      "target": "toolAgent_0",
      "sourceHandle": "serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool",
      "targetHandle": "toolAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "data": {}
    },
    {
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel",
      "source": "chatOpenAI_0",
      "target": "toolAgent_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "targetHandle": "toolAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "data": {}
    },
    {
      "id": "bufferMemory_1-bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory",
      "source": "bufferMemory_1",
      "target": "toolAgent_0",
      "sourceHandle": "bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "targetHandle": "toolAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "data": {}
    }
  ],
  "viewport": {
    "x": 0,
    "y": 0,
    "zoom": 1
  },
  "analysis": {
    "totalNodes": 6,
    "totalEdges": 4,
    "nodeTypes": {
      "customNode": 5,
      "stickyNote": 1
    },
    "edgeTypes": {
      "buttonedge": 4
    },
    "categories": {
      "Tools": 2,
      "Memory": 1,
      "Chat Models": 1,
      "Utilities": 1,
      "Agents": 1
    },
    "inputParams": {
      "calculator_1": [],
      "bufferMemory_1": [
        {
          "label": "Session Id",
          "name": "sessionId",
          "type": "string",
          "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
          "default": "",
          "additionalParams": true,
          "optional": true,
          "id": "bufferMemory_1-input-sessionId-string"
        },
        {
          "label": "Memory Key",
          "name": "memoryKey",
          "type": "string",
          "default": "chat_history",
          "additionalParams": true,
          "id": "bufferMemory_1-input-memoryKey-string"
        }
      ],
      "serpAPI_0": [
        {
          "label": "Connect Credential",
          "name": "credential",
          "type": "credential",
          "credentialNames": [
            "serpApi"
          ],
          "id": "serpAPI_0-input-credential-credential"
        }
      ],
      "chatOpenAI_0": [
        {
          "label": "Connect Credential",
          "name": "credential",
          "type": "credential",
          "credentialNames": [
            "openAIApi"
          ],
          "id": "chatOpenAI_0-input-credential-credential",
          "display": true
        },
        {
          "label": "Model Name",
          "name": "modelName",
          "type": "asyncOptions",
          "loadMethod": "listModels",
          "default": "gpt-4o-mini",
          "id": "chatOpenAI_0-input-modelName-asyncOptions",
          "display": true
        },
        {
          "label": "Temperature",
          "name": "temperature",
          "type": "number",
          "step": 0.1,
          "default": 0.9,
          "optional": true,
          "id": "chatOpenAI_0-input-temperature-number",
          "display": true
        },
        {
          "label": "Streaming",
          "name": "streaming",
          "type": "boolean",
          "default": true,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-streaming-boolean",
          "display": true
        },
        {
          "label": "Max Tokens",
          "name": "maxTokens",
          "type": "number",
          "step": 1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-maxTokens-number",
          "display": true
        },
        {
          "label": "Top Probability",
          "name": "topP",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-topP-number",
          "display": true
        },
        {
          "label": "Frequency Penalty",
          "name": "frequencyPenalty",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-frequencyPenalty-number",
          "display": true
        },
        {
          "label": "Presence Penalty",
          "name": "presencePenalty",
          "type": "number",
          "step": 0.1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-presencePenalty-number",
          "display": true
        },
        {
          "label": "Timeout",
          "name": "timeout",
          "type": "number",
          "step": 1,
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-timeout-number",
          "display": true
        },
        {
          "label": "Strict Tool Calling",
          "name": "strictToolCalling",
          "type": "boolean",
          "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-strictToolCalling-boolean",
          "display": true
        },
        {
          "label": "Stop Sequence",
          "name": "stopSequence",
          "type": "string",
          "rows": 4,
          "optional": true,
          "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
          "additionalParams": true,
          "id": "chatOpenAI_0-input-stopSequence-string",
          "display": true
        },
        {
          "label": "BasePath",
          "name": "basepath",
          "type": "string",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-basepath-string",
          "display": true
        },
        {
          "label": "Proxy Url",
          "name": "proxyUrl",
          "type": "string",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-proxyUrl-string",
          "display": true
        },
        {
          "label": "BaseOptions",
          "name": "baseOptions",
          "type": "json",
          "optional": true,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-baseOptions-json",
          "display": true
        },
        {
          "label": "Allow Image Uploads",
          "name": "allowImageUploads",
          "type": "boolean",
          "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
          "default": false,
          "optional": true,
          "id": "chatOpenAI_0-input-allowImageUploads-boolean",
          "display": true
        },
        {
          "label": "Image Resolution",
          "description": "This parameter controls the resolution in which the model views the image.",
          "name": "imageResolution",
          "type": "options",
          "options": [
            {
              "label": "Low",
              "name": "low"
            },
            {
              "label": "High",
              "name": "high"
            },
            {
              "label": "Auto",
              "name": "auto"
            }
          ],
          "default": "low",
          "optional": false,
          "show": {
            "allowImageUploads": true
          },
          "id": "chatOpenAI_0-input-imageResolution-options",
          "display": true
        },
        {
          "label": "Reasoning Effort",
          "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
          "name": "reasoningEffort",
          "type": "options",
          "options": [
            {
              "label": "Low",
              "name": "low"
            },
            {
              "label": "medium",
              "name": "medium"
            },
            {
              "label": "High",
              "name": "high"
            }
          ],
          "default": "medium",
          "optional": false,
          "additionalParams": true,
          "id": "chatOpenAI_0-input-reasoningEffort-options",
          "display": true
        }
      ],
      "stickyNote_0": [
        {
          "label": "",
          "name": "note",
          "type": "string",
          "rows": 1,
          "placeholder": "Type something here",
          "optional": true,
          "id": "stickyNote_0-input-note-string"
        }
      ],
      "toolAgent_0": [
        {
          "label": "System Message",
          "name": "systemMessage",
          "type": "string",
          "default": "You are a helpful AI assistant.",
          "description": "If Chat Prompt Template is provided, this will be ignored",
          "rows": 4,
          "optional": true,
          "additionalParams": true,
          "id": "toolAgent_0-input-systemMessage-string",
          "display": true
        },
        {
          "label": "Max Iterations",
          "name": "maxIterations",
          "type": "number",
          "optional": true,
          "additionalParams": true,
          "id": "toolAgent_0-input-maxIterations-number",
          "display": true
        },
        {
          "label": "Enable Detailed Streaming",
          "name": "enableDetailedStreaming",
          "type": "boolean",
          "default": false,
          "description": "Stream detailed intermediate steps during agent execution",
          "optional": true,
          "additionalParams": true,
          "id": "toolAgent_0-input-enableDetailedStreaming-boolean",
          "display": true
        }
      ]
    },
    "outputAnchors": {
      "calculator_1": [
        {
          "id": "calculator_1-output-calculator-Calculator|Tool|StructuredTool|BaseLangChain",
          "name": "calculator",
          "label": "Calculator",
          "type": "Calculator | Tool | StructuredTool | BaseLangChain"
        }
      ],
      "bufferMemory_1": [
        {
          "id": "bufferMemory_1-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
          "name": "bufferMemory",
          "label": "BufferMemory",
          "type": "BufferMemory | BaseChatMemory | BaseMemory"
        }
      ],
      "serpAPI_0": [
        {
          "id": "serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool",
          "name": "serpAPI",
          "label": "SerpAPI",
          "type": "SerpAPI | Tool | StructuredTool"
        }
      ],
      "chatOpenAI_0": [
        {
          "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
          "name": "chatOpenAI",
          "label": "ChatOpenAI",
          "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
          "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
        }
      ],
      "stickyNote_0": [
        {
          "id": "stickyNote_0-output-stickyNote-StickyNote",
          "name": "stickyNote",
          "label": "StickyNote",
          "description": "Add a sticky note",
          "type": "StickyNote"
        }
      ],
      "toolAgent_0": [
        {
          "id": "toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable",
          "name": "toolAgent",
          "label": "AgentExecutor",
          "description": "Agent that uses Function Calling to pick the tools and args to call",
          "type": "AgentExecutor | BaseChain | Runnable"
        }
      ]
    },
    "complexity": "complex",
    "patterns": [
      "custom-node-based"
    ]
  },
  "zanaiMapping": {
    "suggestedAgentType": "composed",
    "suggestedComponents": [
      {
        "type": "tool",
        "name": "Calculator",
        "description": "Perform calculations on response",
        "config": {},
        "connections": []
      },
      {
        "type": "memory",
        "name": "Buffer Memory",
        "description": "Retrieve chat messages stored in database",
        "config": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "connections": []
      },
      {
        "type": "tool",
        "name": "Serp API",
        "description": "Wrapper around SerpAPI - a real-time API to access Google search results",
        "config": {},
        "connections": []
      },
      {
        "type": "llm",
        "name": "ChatOpenAI",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "config": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": 0.9,
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": true,
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "connections": []
      },
      {
        "type": "input",
        "name": "Sticky Note",
        "description": "Add a sticky note",
        "config": {
          "note": "LLM has to be function calling compatible"
        },
        "connections": []
      },
      {
        "type": "reasoning",
        "name": "Tool Agent",
        "description": "Agent that uses Function Calling to pick the tools and args to call",
        "config": {
          "tools": [
            "{{calculator_1.data.instance}}",
            "{{serpAPI_0.data.instance}}"
          ],
          "memory": "{{bufferMemory_1.data.instance}}",
          "model": "{{chatOpenAI_0.data.instance}}",
          "chatPromptTemplate": "",
          "systemMessage": "You are a helpful AI assistant.",
          "inputModeration": "",
          "maxIterations": "",
          "enableDetailedStreaming": ""
        },
        "connections": []
      }
    ],
    "requiredConfig": [
      "bufferMemory.memoryKey",
      "chatOpenAI.modelName",
      "chatOpenAI.imageResolution",
      "chatOpenAI.reasoningEffort"
    ],
    "suggestedTools": [
      "calculator",
      "serpAPI"
    ],
    "workflowType": "multi"
  }
}